# Joy-o-Meter 🎉 — Predicting Happiness Intensity with NLP

This project implements a simple linear neural network that predicts the **happiness intensity** of a text using pretrained language embeddings. The work leverages PyTorch, Hugging Face's `transformers`, and other essential tools to build a Joy-o-Meter that quantifies how happy a piece of text sounds.

> **Course:** CS224 — Spring 2025  
> **Assignment:** Homework 1 — Joy-o-Meter  
> **Author:** Ranjitha Narasimhamurthy  

---

## 📝 Project Description

The Joy-o-Meter analyzes text samples and predicts the **happiness score** based on pretrained language representations. You'll:

✅ Use Hugging Face Transformers for pretrained language models  
✅ Extract text embeddings  
✅ Implement a simple linear neural network in PyTorch  
✅ Fit model weights using a closed-form analytic solution  
✅ Visualize predictions and evaluate performance  

---

## 📁 Files

| File                | Description                                  |
|---------------------|----------------------------------------------|
| `Joy_o_meter.ipynb` | Main Jupyter notebook with full implementation and explanation |
| `README.md`         | Project overview and setup instructions |

---

## ⚡ Requirements

Make sure to have the following installed:

```bash
pip install torch transformers pandas matplotlib scikit-learn
